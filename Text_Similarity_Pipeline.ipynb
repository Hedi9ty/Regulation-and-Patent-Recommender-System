{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "path = os.getcwd()\n",
    "sys.path.append(path + '\\FUNCTION')\n",
    "from jieba_split_beta import zh_split\n",
    "from text_mining_beta import text_mining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame({'ID' : range(4), 'Content' : ['吃葡萄不吐葡萄皮', '不吃葡萄到吐葡萄皮', \n",
    "                                                  '扁擔想綁在板凳上，板凳不讓扁擔綁在板凳上',\n",
    "                                                   '扁擔偏要綁在板凳上，板凳偏不讓扁擔綁在板凳上']})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ZH split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 載入繁體版Jieba\n",
    "analyzer = zh_split(path + '\\Dictionary\\dict.txt.big')\n",
    "# 載入自定義字典\n",
    "analyzer.add_dictionary(path + '\\Dictionary\\edu_dict.txt')\n",
    "analyzer.add_dictionary(path + '\\Dictionary\\company_dict.txt')\n",
    "analyzer.add_dictionary(# 載入繁體版Jieba\n",
    "analyzer = zh_split(path + '\\Dictionary\\dict.txt.big')\n",
    "# 載入自定義字典\n",
    "analyzer.add_dictionary(path + '\\Dictionary\\edu_dict.txt')\n",
    "analyzer.add_dictionary(path + '\\Dictionary\\geo_dict.txt')\n",
    "analyzer.add_dictionary(path + '\\Dictionary\\law_dict.txt')\n",
    "# 斷詞\n",
    "analyzer.split(data.Content)\n",
    "analyzer.get_dictionary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 斷詞結果\n",
    "analyzer.split_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer.word_filter(w_len=0, # 過濾單詞字數 <= N的單詞\n",
    "                     path_word=path + '\\Dictionary\\stop_words.txt' # 停止詞字典\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 停止詞過濾結果\n",
    "analyzer.split_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#找出潛在關鍵字\n",
    "analyzer.find_keyword(n=2)\n",
    "#潛在關鍵字結果\n",
    "analyzer.add_word #會按機率跳出潛在的組合字詞，可以透過人工方式加入字典"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 載入 text monong 分析器\n",
    "tm = text_mining(analyzer.split_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dictionary\n",
    "tm.get_dictionary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 計算TF\n",
    "tm.CounterVector()\n",
    "print('TF_VECTOR : ', tm.TF_Vector)\n",
    "# 計算TFIDF\n",
    "tm.TfidfVector()\n",
    "print('TFIDF_VECTOR : ', tm.TFIDF_Vector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSI\n",
    "lsi_result, lsi_model = tm.LSI(tm.TFIDF_Vector, \n",
    "                               n_dimension = 10 #維度\n",
    "                              )\n",
    "# Doc2vec\n",
    "doc_result, doc_model = tm.doc2vec(vector_size = 10, #維度\n",
    "                                   epochs = 50, dbow_words= 1, dm=0, iter=1, window=5\n",
    "                                  )\n",
    "doc_result = [list(enumerate(row)) for row in doc_result]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lsi similarity\n",
    "tm.sim(lsi_result, lsi_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doc2vec similarity\n",
    "tm.sim(doc_result, doc_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensemble\n",
    "(tm.sim(lsi_result, lsi_result) + tm.sim(doc_result, doc_result)) / 2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
